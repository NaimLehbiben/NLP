{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# BLUE SCORING\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "from src.data.data_fetcher import download\n",
    "from src.data.image_loader import encoded_image_loader\n",
    "from src.data.data_processing import DataPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading all necessary data from Google Drive and place it in the \"data\" repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_id', 'caption'], dtype='object')\n",
      "Index(['image_id', 'caption'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# loading the encoded images\n",
    "with open(\"./data/encoded_images_PCA.p\", \"rb\") as f:\n",
    "    encoded_images = pickle.load(f)\n",
    "\n",
    "# loading the dataframes\n",
    "train_data = pd.read_csv(\"./data/flickr_8k_train_dataset.txt\", delimiter='\\t', header=None, names=['image_id', 'caption'])\n",
    "test_data = pd.read_csv(\"./data/flickr_8k_test_dataset.txt\", delimiter='\\t', header=None, names=['image_id', 'caption'])\n",
    "\n",
    "# check columns\n",
    "print(train_data.columns)\n",
    "print(test_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the train and test dataframe in the same way by extracting the encoded images (in vector format) from the dictionary `encoded_images`. Then we convert it into numpy array for matrix manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6000, 100), (1000, 100))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Extraction des noms d'images pour l'entraînement et le test\n",
    "train_image_names = train_data['image_id'].unique()\n",
    "test_image_names = test_data['image_id'].unique()\n",
    "\n",
    "# Création des ensembles de données d'entraînement et de test à partir des images encodées\n",
    "image_features_train = [encoded_images[img] for img in train_image_names if img in encoded_images]\n",
    "image_features_test = [encoded_images[img] for img in test_image_names if img in encoded_images]\n",
    "\n",
    "# Conversion en numpy array\n",
    "image_features_train = np.array(image_features_train)\n",
    "image_features_test = np.array(image_features_test)\n",
    "image_features_train.shape, image_features_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement an unsupervised Nearest Neighbors model that calculated the nearest neighbors given a distance metric and a minimal number of neighbors.\n",
    "\n",
    "Once the model trained on the train dataset we compute the most similar neighbor for an image in the test dataset in order to compute the most similar caption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITrain the model\n",
    "nbrs = NearestNeighbors(n_neighbors=5, algorithm='auto').fit(image_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest train image : [1285 4955 3690 3515 5006]\n"
     ]
    }
   ],
   "source": [
    "# Fonction de recherche des voisins les plus proches\n",
    "def find_nearest_neighbors(test_image_features, k=5):\n",
    "    _, indices = nbrs.kneighbors([test_image_features], n_neighbors=k)\n",
    "    return indices[0]\n",
    "\n",
    "# Exemple de recherche pour une image de test\n",
    "test_image_idx = 0  # Modifier l'index pour tester différentes images\n",
    "test_image_features = image_features_test[test_image_idx]\n",
    "nearest_neighbors = find_nearest_neighbors(test_image_features)\n",
    "print(\"Nearest train image :\", nearest_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest captions :\n",
      "-  <start> A man in a white shirt and sunglasses gazes into the horizon . <end>\n",
      "-  <start> A person in a scuba suit holds a very small lobster . <end>\n",
      "-  <start> A man in a black shirt enjoys a snack while a woman in a white shirt looks confused . <end>\n",
      "-  <start> A goalie is covering his net while two other hockey players chase after the hockey puck . <end>\n",
      "-  <start> Two girls giving the peace sign . <end>\n"
     ]
    }
   ],
   "source": [
    "# Récupération des légendes des voisins les plus proches\n",
    "def get_captions_from_indices(indices):\n",
    "    captions = []\n",
    "    for idx in indices:\n",
    "        img_name = train_image_names[idx]\n",
    "        caption = train_data[train_data['image_id'] == img_name]['caption'].values[0]\n",
    "        captions.append(caption)\n",
    "    return captions\n",
    "\n",
    "nearest_captions = get_captions_from_indices(nearest_neighbors)\n",
    "print(\"Nearest captions :\")\n",
    "for n in nearest_captions:\n",
    "    print(\"- \",n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score BLEU : 0.029573767019698084\n"
     ]
    }
   ],
   "source": [
    "# Caption generation for the test set\n",
    "def generate_captions_for_test_set():\n",
    "    predictions = []\n",
    "    for i in range(len(image_features_test)):\n",
    "        test_image_features = image_features_test[i]\n",
    "        nearest_neighbors = find_nearest_neighbors(test_image_features)\n",
    "        nearest_captions = get_captions_from_indices(nearest_neighbors)\n",
    "        predictions.append(nearest_captions[0])  # Using the nearest one.\n",
    "    return predictions\n",
    "\n",
    "\n",
    "predicted_captions = generate_captions_for_test_set()\n",
    "\n",
    "reference_captions = [test_data[test_data['image_id'] == img]['caption'].values[0].split() for img in test_image_names if img in encoded_images]\n",
    "\n",
    "bleu_score = corpus_bleu([[ref] for ref in reference_captions], [pred.split() for pred in predicted_captions])\n",
    "print(\"Score BLEU :\", bleu_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
